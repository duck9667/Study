{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RamdomForest\n",
    "---\n",
    "랜덤포레스의 배경은 앙상블이다.\n",
    "여러 Base 모델의 예측을 다수결 법칙 또는 평균을 이용해 통합하여 예측 정확성을 향상시키는 방법\n",
    "\n",
    "다음 조건을 만족할때 앙상블 모델은 Base모델보다 우수한 성능을 보여준다\n",
    "- base모델들이 서로 독립적\n",
    "- base모델들이 무작위 예측을 수행하는 모델보다 성능이 좋은 경우 -> 범주가 2개일 때 무작위 예측은 0.5\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00. 개요\n",
    "---\n",
    "- 다수의 의사결정나무모델에 의한 예측을 종합하는 앙상블 방법\n",
    "- 일반적으로 하나의 의사결정나무모델 보다 높은 예측 정확성을 보여줌\n",
    "- 관측치 수에 비해 변수의 수가 많은 고차원 데이터에서 중요 변수 선택 기법으로 널리 활용됨\n",
    "- Bootstrap 기법을 이용하여 다수의 Training data 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01. 핵심 아이디어 (Diversity, Random확보)\n",
    "---\n",
    "1. 여러 개의 Training data를 생성하여 각 데이터마다 개별 의사결정나무모델 구축 -> **Bagging**\n",
    "2. 의사결정나무모델 구축 시 변수 무작위 선택 -> **Random subspace\n",
    "\n",
    "### 1. Bagging(Bootstrap Aggregating) : Diversity 확보  \n",
    "각각의 bootstrap샘플로부터 생성된 모델을 합침  \n",
    "\n",
    "**Bootstrapping**\n",
    "- 샘플링 기법\n",
    "- 각 데이터셋은 **복원 추출**을 통해 **원래 데이터의 수만큼의 크기**를 갖도록 샘플링\n",
    "- 개별 데이터셋을 부스트랩셋이라 부름\n",
    "\n",
    "**Result Aggregating**\n",
    "- Majority voting : 0과 1의 갯수\n",
    "- Weighted voting1 : 0과 1의 Training Accuracy의 합의 평균\n",
    "- Weighted voting2 : 0과 1일의 예측 확률의 평균\n",
    "    \n",
    "### 2. Random subspace : Random 확보\n",
    "분할점에서 변수를 선택할때 매번 무작위 n개 만큼 복원 추출 그 중 가장 잘 설명하는 변수 선택\n",
    "full-grown tree가 될때까지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03. 변수의 중요도  \n",
    "---\n",
    "- 랜덤포레스트는 선형회귀모델/로지스틱회귀모델과는 달리 개별 변수가 통계적으로 얼마나 유의한지에 대한 정보를 제공하지 않음\n",
    "- 대신 랜덤포레스트는 다음과 같은 간접적인 방식으로 변수의 중요도를 결정 ex) OOB error계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04. Hyperparameter  \n",
    "---\n",
    "- 일반적으로 의사결정나무의 수는 2,000개 이상은 필요하다.\n",
    "- 무작위 선택되는 변수의 수는 **분류의 경우 변수 수의 제곱근**, **예측의 경우 변수의 수/3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05. 장점  \n",
    "---  \n",
    "결정 트리의 단점은 훈련 데이터에 오버피팅이 되는 경향이 있다는 것입니다. 여러 개의 결정 트리를 통해 랜덤 포레스트를 만들면 오버피팅 되는 단점을 해결할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06. 앙상블\n",
    "---\n",
    "- **앙상블 효과**  \n",
    "base모델의 오류율이 0.5 보다 낮을 경우 앙상블의 효과가 높아진다.  \n",
    "  \n",
    "  \n",
    "- **앙상블 명명**  \n",
    "앙상블 모델은 어떤 base모델을 쓰느냐에 따라 앙상블 모델의 이름이 달라진다. 랜덤포레스트는 base모델로 의사결정 나무를 이용한 것.\n",
    "\n",
    "\n",
    "- **의사결정나무모델은 앙상블 모델의 베이스로 모델로 활용도가 높다.**  \n",
    "    - 데이터 크기가 방대한 경우에도 모델을 빨리 구축할 수 있음\n",
    "    - 데이터 분포에 대한 전제가 필요하지 않다. (비모수적)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07. 파라미터\n",
    "---\n",
    "\n",
    "- **n_estimators** : 랜덤 포레스트 안의 결정 트리 갯수  \n",
    "n_estimators는 클수록 좋습니다. 결정 트리가 많을수록 더 깔끔한 Decision Boundary가 나오겠죠. 하지만 그만큼 메모리와 훈련 시간이 증가합니다.\n",
    "\n",
    "\n",
    "- **max_features** : 무작위로 선택할 Feature의 개수   \n",
    "max_features=n_features이면 30개의 feature 중 30개의 feature 모두를 선택해 결정 트리를 만듭니다. 단, bootstrap=True이면 30개의 feature에서 복원 추출로 30개를 뽑습니다. 특성 선택의 무작위성이 없어질 뿐 샘플링의 무작위성은 그대로인 것입니다. bootstrap=True는 default 값입니다. 따라서 max_features 값이 크면 랜덤 포레스트의 트리들이 매우 비슷해지고, 가장 두드러진 특성에 맞게 예측을 할 것입니다. max_features 값이 작으면 랜덤 포레스트의 트리들이 서로 매우 달라질 것입니다. 따라서 오버피팅이 줄어들 것입니다. max_features는 일반적으로 Defalut 값을 씁니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 출처\n",
    "------\n",
    "- https://medium.com/@deepvalidation/title-3b0e263605de  \n",
    "- refactorthis.net의 포스트  \n",
    "- https://bkshin.tistory.com/entry\n",
    "- 앙상블 개념 : https://www.youtube.com/watch?v=lIT5-piVtRw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
